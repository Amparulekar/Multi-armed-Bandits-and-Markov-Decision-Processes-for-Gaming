# Multi-armed-Bandits-and-Markov-Decision-Processes-for-Gaming